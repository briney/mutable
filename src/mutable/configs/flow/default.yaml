hidden_size: null
num_layers: 6
num_attention_heads: 20
intermediate_size: null
activation: swiglu
time_embedding_dim: 128
mu_embedding_dim: 128
conditioning_method: adaln
ode_solver: euler
ode_steps: 100
sigma_min: 1.0e-4
timestep_sampling: uniform
logit_normal_mean: 0.0
logit_normal_std: 1.0
dropout: 0.1
attention_dropout: null
hidden_dropout: null
ffn_bias: true
initializer_range: 0.02
layer_norm_eps: 1.0e-5
